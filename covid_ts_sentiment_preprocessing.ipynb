{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fl7PXLDqUn9",
        "outputId": "a4059511-a416-4694-d7a5-15d147a9fc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "folder_path = \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "qwHiXHw0h9Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# covid time series preprocessing\n",
        "def process_ts():\n",
        "\n",
        "    # read data\n",
        "    case_death_df = pd.read_csv(folder_path + \"/full_data.csv\")\n",
        "    vaccination_df = pd.read_csv(folder_path + \"/vaccinations.csv\")\n",
        "    testing_df = pd.read_csv(folder_path + \"/covid-testing-all-observations.csv\")\n",
        "    hospitalization_df = pd.read_csv(folder_path + \"/covid-hospitalizations.csv\")\n",
        "\n",
        "    # only keep US data\n",
        "    case_death_df = case_death_df[case_death_df[\"location\"] == \"United States\"]\n",
        "    vaccination_df = vaccination_df[vaccination_df[\"location\"] == \"United States\"]\n",
        "    testing_df = testing_df[testing_df[\"Entity\"] == \"United States - tests performed\"]\n",
        "    hospitalization_df = hospitalization_df[hospitalization_df[\"entity\"] == \"United States\"]\n",
        "\n",
        "    # data cleaning\n",
        "    case_death_df = case_death_df.drop(columns=[\"location\"])\n",
        "    vaccination_df = vaccination_df.drop(columns=[\"location\", \"iso_code\"])\n",
        "    testing_df.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
        "    testing_df = testing_df.drop(columns=[\"Entity\", \"ISO code\", \"Source URL\", \"Source label\", \"Notes\"])\n",
        "\n",
        "    hospitalization_df = (\n",
        "        hospitalization_df.pivot_table(index=\"date\", columns=\"indicator\", values=\"value\")\n",
        "          .reset_index()\n",
        "          .sort_values(\"date\")\n",
        "    )\n",
        "\n",
        "    # join dataframes\n",
        "    merged = pd.merge(case_death_df , vaccination_df, on=\"date\", how=\"inner\")\n",
        "    merged = pd.merge(merged , testing_df, on=\"date\", how=\"inner\")\n",
        "    timeseries_df = pd.merge(merged , hospitalization_df, on=\"date\", how=\"inner\")\n",
        "\n",
        "    # Average out new cases and new deaths data (previously collected weekly)\n",
        "    timeseries_df['new_cases_smoothed'] = timeseries_df['new_cases'].copy()\n",
        "    timeseries_df['new_deaths_smoothed'] = timeseries_df['new_deaths'].copy()\n",
        "\n",
        "    for index, row in tqdm(timeseries_df.iterrows(), total=len(timeseries_df)):\n",
        "        if row['new_cases'] > 0 and index >= 6:\n",
        "            weekly_cases = row['new_cases']\n",
        "            daily_cases = weekly_cases / 7\n",
        "            for i in range(7):\n",
        "                timeseries_df.loc[index - i, 'new_cases_smoothed'] = daily_cases\n",
        "\n",
        "        if row['new_deaths'] > 0 and index >= 6:\n",
        "            weekly_deaths = row['new_deaths']\n",
        "            daily_deaths = weekly_deaths / 7\n",
        "            for i in range(7):\n",
        "                timeseries_df.loc[index - i, 'new_deaths_smoothed'] = daily_deaths\n",
        "\n",
        "    timeseries_df['new_cases'] = timeseries_df['new_cases_smoothed']\n",
        "    timeseries_df['new_deaths'] = timeseries_df['new_deaths_smoothed']\n",
        "\n",
        "    # Drop the temporary smoothed columns\n",
        "    timeseries_df = timeseries_df.drop(columns=['new_cases_smoothed', 'new_deaths_smoothed', 'total_boosters_per_hundred'])\n",
        "    timeseries_df.loc[0, 'new_cases'] = timeseries_df.loc[0, 'new_cases']/7\n",
        "    timeseries_df.loc[0, 'new_deaths'] = timeseries_df.loc[0, 'new_deaths']/7\n",
        "\n",
        "    # Display the updated DataFrame with smoothed values\n",
        "    timeseries_df.to_csv(folder_path + \"/covid_us_timeseries.csv\", index=False)\n",
        "\n",
        "    print(f\"Processed covid timeseries dataset saved to: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y14nrL6ltPHN",
        "outputId": "357fff2e-51e9-47df-a33c-e439f9032a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed covid timeseries dataset saved to: /content/gdrive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentiment preprocessing\n",
        "def process_sentiment():\n",
        "    sentiment_df = pd.concat([chunk for chunk in tqdm(pd.read_csv(folder_path + \"/COVID19_twitter_full_dataset.csv\", chunksize=1000), desc='Loading data')])\n",
        "    sentiment_df_us = sentiment_df[sentiment_df['country/region'] == 'United States']\n",
        "    sentiment_df_us.to_csv(folder_path + \"/covid_us_sentiment.csv\", index=False)"
      ],
      "metadata": {
        "id": "FlUz3Roxh0bV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac3484-b48a-4293-96f2-052ba93e6109"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 198379it [09:27, 349.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_ts()\n",
        "process_sentiment()"
      ],
      "metadata": {
        "id": "dJRx9_dpzlvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}